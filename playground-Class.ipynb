{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('T_1',), ('T_2',), ('T_0',)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(123)\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# cerate a dummy timeseries\n",
    "shape=(120,3)\n",
    "freq='D'\n",
    "data = pd.DataFrame(np.random.randn(*shape)*np.random.randint(1,1e6,size=(shape[0],1)),\n",
    "                           index=pd.date_range(\n",
    "                               end=pd.Timestamp.today().date(),\n",
    "                               periods=shape[0], freq=freq), \n",
    "                           columns=[f'T_{c}' for c in range(shape[1])])\n",
    "skinny = data.reset_index().melt(id_vars='index')\n",
    "skin_grpd = skinny.groupby(['variable', pd.Grouper(key='index', freq=freq)]).sum()\n",
    "\n",
    "groups=list({g[:-1] for g in skin_grpd.index})\n",
    "ts_dict = {g:skin_grpd.loc[g]['value'].astype('int') for g in groups}\n",
    "groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ARIMA` from statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesSplit:\n",
    "    \"\"\"To split timeseries into train and validation index\n",
    "    \"\"\"\n",
    "    def __init__(self, ts_len, pred_steps, n_windows, gap=0):\n",
    "        self.n = ts_len-3\n",
    "        self.steps = pred_steps\n",
    "        self.n_w = n_windows\n",
    "        self.gap = gap\n",
    "        \n",
    "    def split(self):\n",
    "        return[(np.arange(self.n-n_w).tolist(), \n",
    "                np.arange(self.n-n_w-self.steps-self.gap).tolist(), \n",
    "                np.arange(self.n-n_w-self.steps, self.n-n_w).tolist()) for n_w in range(self.n_w)]\n",
    "    \n",
    "\n",
    "def mape(y_true, y_pred, tol=1e-6):\n",
    "    return np.abs(y_pred-y_true)/(np.abs(y_true)+tol)\n",
    "\n",
    "# make a test case\n",
    "# TimeSeriesSplit(10,2,3).split()\n",
    "\n",
    "from functools import *\n",
    "from ray import tune\n",
    "import ray\n",
    "from ray.tune.schedulers import ASHAScheduler, AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "from ray.tune.suggest import ConcurrencyLimiter\n",
    "from ray.tune.suggest.skopt import SkOptSearch\n",
    "from ray.tune import JupyterNotebookReporter\n",
    "from ray.tune import Analysis, ExperimentAnalysis\n",
    "\n",
    "fit_params = {\n",
    "    'p': tune.randint(0,3),\n",
    "    'd': tune.randint(0,3),\n",
    "    'q': tune.randint(0,3),\n",
    "    'P': tune.randint(0,3),\n",
    "    'D': tune.randint(0,3),\n",
    "    'Q': tune.randint(0,3),\n",
    "    's': tune.randint(0,12),\n",
    "    't_1': tune.randint(0,1),\n",
    "    't_2': tune.randint(0,1),\n",
    "    't_3': tune.randint(0,1),\n",
    "    'enforce_stationarity': tune.choice([True, False]),\n",
    "    'enforce_invertibility': tune.choice([True, False]),\n",
    "    'concentrate_scale': tune.choice([True, False]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class UniVarTs():\n",
    "    verbose=2\n",
    "    \n",
    "    def __init__(self, ts, index, params,\n",
    "                 pred_steps, n_windows,\n",
    "                 error_func,trials=3, local_dir='./results'):\n",
    "        self.ts=ts\n",
    "        self.index='_'.join(map(str,index))\n",
    "        self.local_dir=local_dir\n",
    "        self.pred_steps=pred_steps\n",
    "        self.n_windows=n_windows\n",
    "        self.error_func=error_func\n",
    "        self.params=params\n",
    "        self.reporter=JupyterNotebookReporter(overwrite=True)\n",
    "        self.set_algo() # TODO : change based on algo choosen\n",
    "        self.trials=trials\n",
    "        \n",
    "    @staticmethod\n",
    "    def trainable(config, \n",
    "                  ts=None, \n",
    "                  pred_steps=None, \n",
    "                  n_windows=None, \n",
    "                  error_func=None):\n",
    "\n",
    "        tscv=TimeSeriesSplit(len(ts), pred_steps, n_windows)\n",
    "\n",
    "        p, d, q = config['p'], config['d'],config['q']\n",
    "        P, D, Q, s = config['P'],config['D'],config['Q'], config['s']\n",
    "        t1, t2, t3 = config['t_1'],config['t_2'],config['t_3']\n",
    "\n",
    "        error = 0\n",
    "        for _, train_idx, test_idx in tscv.split():\n",
    "            X_train, X_val = ts[train_idx], ts[test_idx]\n",
    "\n",
    "            fit_obj = ARIMA(X_train, \n",
    "                            order=(p,d,q), \n",
    "                            seasonal_order=(P,D,Q,s), \n",
    "                            trend=[t1,t2,t3], \n",
    "                            enforce_stationarity=config['enforce_stationarity'],\n",
    "                            enforce_invertibility=config['enforce_invertibility'],\n",
    "                            concentrate_scale=config['concentrate_scale']).fit()\n",
    "\n",
    "            forecast = fit_obj.forecast(steps=tscv.steps)\n",
    "            error += error_func(X_val[-1], forecast[-1])\n",
    "        tune.report(mape=error)\n",
    "        \n",
    "    def set_algo(self, concurent=1):\n",
    "        algo = SkOptSearch(metric=\"mape\", mode=\"min\")\n",
    "        self.algo = ConcurrencyLimiter(algo, max_concurrent=concurent)\n",
    "        \n",
    "    def tune(self):\n",
    "        self.analysis = tune.run(\n",
    "            tune.with_parameters(self.trainable, ts=self.ts, pred_steps=self.pred_steps, \n",
    "                                 error_func=self.error_func, n_windows=self.n_windows),\n",
    "            metric=\"mape\",\n",
    "            mode=\"min\",\n",
    "            name=self.index,\n",
    "            search_alg=self.algo,\n",
    "            num_samples=self.trials, \n",
    "            local_dir=self.local_dir,\n",
    "            raise_on_failed_trial=False,\n",
    "            checkpoint_at_end=True,\n",
    "            config=self.params,\n",
    "            verbose=verbose,\n",
    "            progress_reporter=self.reporter,\n",
    "        )\n",
    "    \n",
    "    @ray.method(num_returns=1)       \n",
    "    def get_analysis(self):\n",
    "        return self.analysis\n",
    "    \n",
    "    @ray.method(num_returns=1) \n",
    "    def best_result(self):\n",
    "        return self.analysis.best_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SkOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-08 15:37:48,349\tINFO services.py:1174 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '172.16.93.66',\n",
       " 'raylet_ip_address': '172.16.93.66',\n",
       " 'redis_address': '172.16.93.66:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-02-08_15-37-47_894569_24405/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-02-08_15-37-47_894569_24405/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-02-08_15-37-47_894569_24405',\n",
       " 'metrics_export_port': 58030,\n",
       " 'node_id': 'bd8816653dce1237faec3815f3eefc7ac7d154ff104b16b7e97475bd'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(ignore_reinit_error=True, local_mode=True, num_cpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Actor(UniVarTs,a67dc375e60ddd1a23bd3bb901000000),\n",
       " Actor(UniVarTs,63964fa4841d4a2ecb45751801000000),\n",
       " Actor(UniVarTs,69a6825d641b461327313d1c01000000)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UniVarTs_ray = ray.remote(UniVarTs)\n",
    "l_ = [UniVarTs.remote(ts,grp,fit_params,3,5,mape,trials=10) for grp,ts in ts_dict.items()]\n",
    "l_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 1.9/62.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/4 CPUs, 0/0 GPUs, 0.0/37.21 GiB heap, 0.0/12.84 GiB objects<br>Result logdir: /home/ec2-user/SageMaker/skopt/results/T_1<br>Number of trials: 1/10 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  D</th><th style=\"text-align: right;\">  P</th><th style=\"text-align: right;\">  Q</th><th style=\"text-align: right;\">  concentrate_scale</th><th style=\"text-align: right;\">  d</th><th style=\"text-align: right;\">  enforce_invertibility</th><th style=\"text-align: right;\">  enforce_stationarity</th><th style=\"text-align: right;\">  p</th><th style=\"text-align: right;\">  q</th><th style=\"text-align: right;\">  s</th><th style=\"text-align: right;\">  t_1</th><th style=\"text-align: right;\">  t_2</th><th style=\"text-align: right;\">  t_3</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_inner_9cd7f93a</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">  2</td><td style=\"text-align: right;\">  3</td><td style=\"text-align: right;\">  2</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\"> 10</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">    0</td><td style=\"text-align: right;\">    0</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-08 15:38:08,687\tWARNING session.py:51 -- A Tune session already exists in the current process. If you are using ray.init(local_mode=True), you must set ray.init(..., num_cpus=1, num_gpus=1) to limit available concurrency.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _inner_9cd7f93a:\n",
      "  date: 2021-02-08_15-38-08\n",
      "  done: false\n",
      "  experiment_id: 6b639dca08e54af2a3590c7c58601e9e\n",
      "  hostname: ip-172-16-93-66\n",
      "  iterations_since_restore: 1\n",
      "  mape: 14.096666630783071\n",
      "  node_ip: 172.16.93.66\n",
      "  pid: 24405\n",
      "  time_since_restore: 13.347153663635254\n",
      "  time_this_iter_s: 13.347153663635254\n",
      "  time_total_s: 13.347153663635254\n",
      "  timestamp: 1612798688\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 9cd7f93a\n",
      "  \n",
      "Result for _inner_9cd7f93a:\n",
      "  date: 2021-02-08_15-38-08\n",
      "  done: true\n",
      "  experiment_id: 6b639dca08e54af2a3590c7c58601e9e\n",
      "  experiment_tag: 1_D=2,P=3,Q=2,concentrate_scale=True,d=1,enforce_invertibility=False,enforce_stationarity=True,p=1,q=1,s=10,t_1=1,t_2=0,t_3=0\n",
      "  hostname: ip-172-16-93-66\n",
      "  iterations_since_restore: 1\n",
      "  mape: 14.096666630783071\n",
      "  node_ip: 172.16.93.66\n",
      "  pid: 24405\n",
      "  time_since_restore: 13.347153663635254\n",
      "  time_this_iter_s: 13.347153663635254\n",
      "  time_total_s: 13.347153663635254\n",
      "  timestamp: 1612798688\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 9cd7f93a\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-08 15:38:08,916\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 576, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 651, in _inner\n",
      "    inner(config, checkpoint_dir=None)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 645, in inner\n",
      "    fn(config, **fn_kwargs)\n",
      "  File \"<ipython-input-3-506cee2b51e9>\", line 42, in trainable\n",
      "    concentrate_scale=config['concentrate_scale']).fit()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/arima/model.py\", line 327, in fit\n",
      "    **method_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\", line 659, in fit\n",
      "    skip_hessian=True, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/base/model.py\", line 526, in fit\n",
      "    full_output=full_output)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/base/optimizer.py\", line 218, in _fit\n",
      "    hess=hessian)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/base/optimizer.py\", line 440, in _fit_lbfgs\n",
      "    **extra_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 199, in fmin_l_bfgs_b\n",
      "    **opts)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 345, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 290, in func_and_grad\n",
      "    f = fun(x, *args)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/scipy/optimize/optimize.py\", line 327, in function_wrapper\n",
      "    return function(*(wrapper_args + args))\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/base/model.py\", line 500, in f\n",
      "    return -self.loglike(params, *args) / nobs\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\", line 889, in loglike\n",
      "    loglike = self.ssm.loglike(complex_step=complex_step, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/statespace/kalman_filter.py\", line 977, in loglike\n",
      "    kfilter = self._filter(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/statespace/kalman_filter.py\", line 897, in _filter\n",
      "    self._initialize_state(prefix=prefix, complex_step=complex_step)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/statespace/representation.py\", line 950, in _initialize_state\n",
      "    complex_step=complex_step)\n",
      "  File \"statsmodels/tsa/statespace/_representation.pyx\", line 1341, in statsmodels.tsa.statespace._representation.dStatespace.initialize\n",
      "  File \"statsmodels/tsa/statespace/_representation.pyx\", line 1334, in statsmodels.tsa.statespace._representation.dStatespace.initialize\n",
      "  File \"statsmodels/tsa/statespace/_initialization.pyx\", line 288, in statsmodels.tsa.statespace._initialization.dInitialization.initialize\n",
      "  File \"statsmodels/tsa/statespace/_initialization.pyx\", line 406, in statsmodels.tsa.statespace._initialization.dInitialization.initialize_stationary_stationary_cov\n",
      "  File \"statsmodels/tsa/statespace/_tools.pyx\", line 1284, in statsmodels.tsa.statespace._tools._dsolve_discrete_lyapunov\n",
      "numpy.linalg.LinAlgError: Schur decomposition solver error.\n",
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "    raise e\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 576, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 651, in _inner\n",
      "    inner(config, checkpoint_dir=None)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 645, in inner\n",
      "    fn(config, **fn_kwargs)\n",
      "  File \"<ipython-input-3-506cee2b51e9>\", line 42, in trainable\n",
      "    concentrate_scale=config['concentrate_scale']).fit()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/arima/model.py\", line 327, in fit\n",
      "    **method_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\", line 659, in fit\n",
      "    skip_hessian=True, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/base/model.py\", line 526, in fit\n",
      "    full_output=full_output)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/base/optimizer.py\", line 218, in _fit\n",
      "    hess=hessian)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/base/optimizer.py\", line 440, in _fit_lbfgs\n",
      "    **extra_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 199, in fmin_l_bfgs_b\n",
      "    **opts)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 345, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 290, in func_and_grad\n",
      "    f = fun(x, *args)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/scipy/optimize/optimize.py\", line 327, in function_wrapper\n",
      "    return function(*(wrapper_args + args))\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/base/model.py\", line 500, in f\n",
      "    return -self.loglike(params, *args) / nobs\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\", line 889, in loglike\n",
      "    loglike = self.ssm.loglike(complex_step=complex_step, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/statespace/kalman_filter.py\", line 977, in loglike\n",
      "    kfilter = self._filter(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/statespace/kalman_filter.py\", line 897, in _filter\n",
      "    self._initialize_state(prefix=prefix, complex_step=complex_step)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/statespace/representation.py\", line 950, in _initialize_state\n",
      "    complex_step=complex_step)\n",
      "  File \"statsmodels/tsa/statespace/_representation.pyx\", line 1341, in statsmodels.tsa.statespace._representation.dStatespace.initialize\n",
      "  File \"statsmodels/tsa/statespace/_representation.pyx\", line 1334, in statsmodels.tsa.statespace._representation.dStatespace.initialize\n",
      "  File \"statsmodels/tsa/statespace/_initialization.pyx\", line 288, in statsmodels.tsa.statespace._initialization.dInitialization.initialize\n",
      "  File \"statsmodels/tsa/statespace/_initialization.pyx\", line 406, in statsmodels.tsa.statespace._initialization.dInitialization.initialize_stationary_stationary_cov\n",
      "  File \"statsmodels/tsa/statespace/_tools.pyx\", line 1284, in statsmodels.tsa.statespace._tools._dsolve_discrete_lyapunov\n",
      "numpy.linalg.LinAlgError: Schur decomposition solver error.\n",
      "\n",
      "2021-02-08 15:38:09,322\tERROR trial_runner.py:570 -- Trial _inner_a4d591a6: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 540, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 514, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\", line 47, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/worker.py\", line 1386, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=24405, ip=172.16.93.66)\n",
      "  File \"python/ray/_raylet.pyx\", line 480, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 432, in ray._raylet.execute_task.function_executor\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trainable.py\", line 167, in train_buffered\n",
      "    result = self.train()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/trainable.py\", line 226, in train\n",
      "    result = self.step()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
      "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=24405, ip=172.16.93.66)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 576, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 651, in _inner\n",
      "    inner(config, checkpoint_dir=None)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 645, in inner\n",
      "    fn(config, **fn_kwargs)\n",
      "  File \"<ipython-input-3-506cee2b51e9>\", line 42, in trainable\n",
      "    concentrate_scale=config['concentrate_scale']).fit()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/arima/model.py\", line 327, in fit\n",
      "    **method_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\", line 659, in fit\n",
      "    skip_hessian=True, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/base/model.py\", line 526, in fit\n",
      "    full_output=full_output)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/base/optimizer.py\", line 218, in _fit\n",
      "    hess=hessian)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/base/optimizer.py\", line 440, in _fit_lbfgs\n",
      "    **extra_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 199, in fmin_l_bfgs_b\n",
      "    **opts)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 345, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 290, in func_and_grad\n",
      "    f = fun(x, *args)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/scipy/optimize/optimize.py\", line 327, in function_wrapper\n",
      "    return function(*(wrapper_args + args))\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/base/model.py\", line 500, in f\n",
      "    return -self.loglike(params, *args) / nobs\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\", line 889, in loglike\n",
      "    loglike = self.ssm.loglike(complex_step=complex_step, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/statespace/kalman_filter.py\", line 977, in loglike\n",
      "    kfilter = self._filter(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/statespace/kalman_filter.py\", line 897, in _filter\n",
      "    self._initialize_state(prefix=prefix, complex_step=complex_step)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/statespace/representation.py\", line 950, in _initialize_state\n",
      "    complex_step=complex_step)\n",
      "  File \"statsmodels/tsa/statespace/_representation.pyx\", line 1341, in statsmodels.tsa.statespace._representation.dStatespace.initialize\n",
      "  File \"statsmodels/tsa/statespace/_representation.pyx\", line 1334, in statsmodels.tsa.statespace._representation.dStatespace.initialize\n",
      "  File \"statsmodels/tsa/statespace/_initialization.pyx\", line 288, in statsmodels.tsa.statespace._initialization.dInitialization.initialize\n",
      "  File \"statsmodels/tsa/statespace/_initialization.pyx\", line 406, in statsmodels.tsa.statespace._initialization.dInitialization.initialize_stationary_stationary_cov\n",
      "  File \"statsmodels/tsa/statespace/_tools.pyx\", line 1284, in statsmodels.tsa.statespace._tools._dsolve_discrete_lyapunov\n",
      "numpy.linalg.LinAlgError: Schur decomposition solver error.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _inner_a4d591a6:\n",
      "  {}\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "2021-02-08 15:38:13,006\tWARNING session.py:51 -- A Tune session already exists in the current process. If you are using ray.init(local_mode=True), you must set ray.init(..., num_cpus=1, num_gpus=1) to limit available concurrency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for _inner_a5385962:\n",
      "  date: 2021-02-08_15-38-12\n",
      "  done: false\n",
      "  experiment_id: f02aaa3b81174a91bb9b6b5c7c2f5810\n",
      "  hostname: ip-172-16-93-66\n",
      "  iterations_since_restore: 1\n",
      "  mape: 15.869465361519547\n",
      "  node_ip: 172.16.93.66\n",
      "  pid: 24405\n",
      "  time_since_restore: 3.6487085819244385\n",
      "  time_this_iter_s: 3.6487085819244385\n",
      "  time_total_s: 3.6487085819244385\n",
      "  timestamp: 1612798692\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: a5385962\n",
      "  \n",
      "Result for _inner_a5385962:\n",
      "  date: 2021-02-08_15-38-12\n",
      "  done: true\n",
      "  experiment_id: f02aaa3b81174a91bb9b6b5c7c2f5810\n",
      "  experiment_tag: 3_D=1,P=2,Q=0,concentrate_scale=True,d=2,enforce_invertibility=True,enforce_stationarity=True,p=3,q=0,s=7,t_1=1,t_2=1,t_3=0\n",
      "  hostname: ip-172-16-93-66\n",
      "  iterations_since_restore: 1\n",
      "  mape: 15.869465361519547\n",
      "  node_ip: 172.16.93.66\n",
      "  pid: 24405\n",
      "  time_since_restore: 3.6487085819244385\n",
      "  time_this_iter_s: 3.6487085819244385\n",
      "  time_total_s: 3.6487085819244385\n",
      "  timestamp: 1612798692\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: a5385962\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/statespace/sarimax.py:975: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/statespace/sarimax.py:1006: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/statsmodels/tsa/base/tsa_model.py:162: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  % freq, ValueWarning)\n",
      "2021-02-08 15:53:59,594\tERROR import_thread.py:89 -- ImportThread: Connection closed by server.\n"
     ]
    }
   ],
   "source": [
    "tune_list = [l.tune.remote() for l in l_]\n",
    "tune_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ObjectRef(e11fe2800445c79a27c0dca5954f99af427c13c20100000001000000)],\n",
       " [ObjectRef(34c9c2094e42fdbfcc0320e00aa0584cd481d0b90100000001000000),\n",
       "  ObjectRef(747754f46b61f47d42867781e3b6e074ed2613070100000001000000)])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.wait(tune_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis0 = Analysis(\"./results/T_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis0.dataframe().sort_values('mape').iloc[0,:]   #get_best_results(metric=\"mape\", mode=\"min\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eanalysis0 = ExperimentAnalysis(\"./results/T_0/experiment_state-2021-02-03_14-32-16.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eanalysis0.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_obj = ray.get(l_[2].get_analysis.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp =groups[0]\n",
    "t_s = UniVarTs.remote(ts_dict[grp],grp,fit_params,3,5,mape,trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_s.tune.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis_skOpt.results_df.sort_values('mean_accuracy', ascending=False).iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
